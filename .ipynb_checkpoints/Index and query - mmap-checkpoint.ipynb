{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query lexer. Very beta\n",
    "\n",
    "It works rather well, almost surprisingly. Only with and or or, and parenthesis, I did not really test the quotes and not operator (spoiler alert : it means they don't work. at all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:37:32.216006",
     "start_time": "2016-11-02T14:37:32.067995"
    },
    "code_folding": [
     47
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Search query parser\n",
    "\n",
    "version 2006-03-09\n",
    "\n",
    "This search query parser uses the excellent Pyparsing module \n",
    "(http://pyparsing.sourceforge.net/) to parse search queries by users.\n",
    "-------------------------------------------------------------------------------\n",
    "Copyright (c) 2006, Estrate, the Netherlands\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification,\n",
    "are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this\n",
    "  list of conditions and the following disclaimer.\n",
    "* Redistributions in binary form must reproduce the above copyright notice,\n",
    "  this list of conditions and the following disclaimer in the documentation \n",
    "  and/or other materials provided with the distribution.\n",
    "* Neither the name of Estrate nor the names of its contributors may be used\n",
    "  to endorse or promote products derived from this software without specific\n",
    "  prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\n",
    "ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; \n",
    "LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON \n",
    "ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT \n",
    "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS \n",
    "SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "CONTRIBUTORS:\n",
    "- Steven Mooij\n",
    "- Rudolph Froger\n",
    "- Paul McGuire\n",
    "\n",
    "\n",
    "~~ End of notice\n",
    "\n",
    "I did not alter the structure of this thing a lot. Mostly modified it to work in my implementation of the index,\n",
    "which uses tuples docid + score instead of single ids. Thus some things might not work yet.\n",
    "Also hurray for global variables and definitions, because I didn't want to write more classes.\n",
    "Wildcard and not search are broken. I didn't test them anyway.\n",
    "\"\"\"\n",
    "from pyparsing import Word, alphanums, Keyword, Group, Combine, Forward, Suppress, Optional, OneOrMore, oneOf\n",
    "\n",
    "class SearchQueryParser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._methods = {\n",
    "            'and': self.evaluateAnd,\n",
    "            'or': self.evaluateOr,\n",
    "            'not': self.evaluateNot,\n",
    "            'parenthesis': self.evaluateParenthesis,\n",
    "            'quotes': self.evaluateQuotes,\n",
    "            'word': self.evaluateWord,\n",
    "            'wordwildcard': self.evaluateWordWildcard,\n",
    "        }\n",
    "        self._parser = self.parser()\n",
    "    \n",
    "    def parser(self):\n",
    "        operatorOr = Forward()\n",
    "        \n",
    "        operatorWord = Group(Combine(Word(alphanums) + Suppress('*'))).setResultsName('wordwildcard') | \\\n",
    "                            Group(Word(alphanums)).setResultsName('word')\n",
    "        \n",
    "        operatorQuotesContent = Forward()\n",
    "        operatorQuotesContent << (\n",
    "            (operatorWord + operatorQuotesContent) | operatorWord\n",
    "        )\n",
    "        \n",
    "        operatorQuotes = Group(\n",
    "            Suppress('\"') + operatorQuotesContent + Suppress('\"')\n",
    "        ).setResultsName(\"quotes\") | operatorWord\n",
    "        \n",
    "        operatorParenthesis = Group(\n",
    "            (Suppress(\"(\") + operatorOr + Suppress(\")\"))\n",
    "        ).setResultsName(\"parenthesis\") | operatorQuotes\n",
    "\n",
    "        operatorNot = Forward()\n",
    "        operatorNot << (Group(\n",
    "            Suppress(Keyword(\"not\", caseless=True)) + operatorNot\n",
    "        ).setResultsName(\"not\") | operatorParenthesis)\n",
    "\n",
    "        operatorAnd = Forward()\n",
    "        operatorAnd << (Group(\n",
    "            operatorNot + Suppress(Keyword(\"and\", caseless=True)) + operatorAnd\n",
    "        ).setResultsName(\"and\") | Group(\n",
    "            operatorNot + OneOrMore(~oneOf(\"and or\") + operatorAnd)\n",
    "        ).setResultsName(\"and\") | operatorNot)\n",
    "        \n",
    "        operatorOr << (Group(\n",
    "            operatorAnd + Suppress(Keyword(\"or\", caseless=True)) + operatorOr\n",
    "        ).setResultsName(\"or\") | operatorAnd)\n",
    "\n",
    "        return operatorOr.parseString\n",
    "\n",
    "    def evaluateAnd(self, argument):\n",
    "        left = self.evaluate(argument[0])\n",
    "        right = self.evaluate(argument[1])\n",
    "        \n",
    "        found = set(left.keys()).intersection(set(right.keys()))\n",
    "        scores = {}\n",
    "        for key in found:\n",
    "            scores[key] = left[key] + right[key]\n",
    "        return scores\n",
    "\n",
    "    def evaluateOr(self, argument):\n",
    "        scores = {}\n",
    "        for i in range(0,2):\n",
    "            localresults = self.evaluate(argument[i])\n",
    "            for key in localresults.keys():\n",
    "                    scores[key] = scores.setdefault(key, 0) + localresults[key]\n",
    "        return scores\n",
    "\n",
    "    def evaluateNot(self, argument):\n",
    "        return self.GetNot(self.evaluate(argument[0]))\n",
    "\n",
    "    def evaluateParenthesis(self, argument):\n",
    "        return self.evaluate(argument[0])\n",
    "\n",
    "    def evaluateQuotes(self, argument):\n",
    "        r = Set()\n",
    "        search_terms = []\n",
    "        for item in argument:\n",
    "            search_terms.append(item[0])\n",
    "            if len(r) == 0:\n",
    "                r = self.evaluate(item)\n",
    "            else:\n",
    "                r = r.intersection(self.evaluate(item))\n",
    "        return self.GetQuotes(' '.join(search_terms), r)\n",
    "\n",
    "    def evaluateWord(self, argument):\n",
    "        return self.GetWord(argument[0])\n",
    "\n",
    "    def evaluateWordWildcard(self, argument):\n",
    "        return self.GetWordWildcard(argument[0])\n",
    "        \n",
    "    def evaluate(self, argument):\n",
    "        return self._methods[argument.getName()](argument)\n",
    "\n",
    "    def Parse(self, query):\n",
    "        #print self._parser(query)[0]\n",
    "        return self.evaluate(self._parser(query)[0])\n",
    "\n",
    "    def GetWord(self, word):\n",
    "        return query(word)\n",
    "\n",
    "    def GetWordWildcard(self, word):\n",
    "        return query(word)\n",
    "\n",
    "    def GetQuotes(self, search_string, tmp_result):\n",
    "        return query(search_string, mode=\"and\")\n",
    "\n",
    "    def GetNot(self, not_set):\n",
    "        return Set().difference(not_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "204184b1-84df-45ed-ab85-d89af73f01d1"
    }
   },
   "source": [
    "# Indexer and querying system\n",
    "\n",
    "This notebook provides a fonctionnal system to index a bunch of text document, and to run fast text queries against the index.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:36:38.678420",
     "start_time": "2016-11-02T14:36:37.881919"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "f983e209-828d-4237-beac-fd05f1439232"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import *\n",
    "from nltk.tokenize import *\n",
    "\n",
    "from os import listdir, mkdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "import mmap\n",
    "\n",
    "from tqdm import *\n",
    "\n",
    "import math\n",
    "import operator\n",
    "import pickle\n",
    "import json\n",
    "import re\n",
    "\n",
    "# from joblib import Parallel, delayed # Needed only if you use parallel in parsefile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:36:41.813304",
     "start_time": "2016-11-02T14:36:41.802294"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "f9d1e156-1248-47ae-9b48-5a2e742b57b2"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer() # Stemmer used to simplify words \n",
    "cachedStopWords = stopwords.words(\"english\") # Used to filter out useless words like this, the, a, ...\n",
    "docs = listdir(\"latimes_cleaned\")\n",
    "stemdb = {} # \n",
    "index = {}\n",
    "indexed = {}\n",
    "termcounts = {}\n",
    "titles = {}\n",
    "artcount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:36:42.981231",
     "start_time": "2016-11-02T14:36:42.975249"
    },
    "collapsed": true,
    "nbpresent": {
     "id": "5673b0d2-fd2f-495a-b8a7-9dc0781912f0"
    }
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('data_cache/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('data_cache/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:38:26.108854",
     "start_time": "2016-11-02T14:38:26.070872"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "ddeb4682-6fe5-44d7-ba78-8e602ead9385"
    }
   },
   "outputs": [],
   "source": [
    "def mergeindex(globalindex, localindex, docid):\n",
    "    for key in localindex.keys():\n",
    "        globalindex.setdefault(key,[]).append((docid, localindex[key]))\n",
    "\n",
    "def updatecount(globalcounts, localcounts):\n",
    "    for key in localcounts.keys():\n",
    "        globalcounts[key] = globalcounts.setdefault(key, 0) + 1\n",
    "\n",
    "\n",
    "def parsestring(words):\n",
    "    local_index = {}\n",
    "    for word in words:\n",
    "        if not word in cachedStopWords:\n",
    "            try:\n",
    "                stemmed = stemdb[word]\n",
    "            except:\n",
    "                stemmed = stemmer.stem(word)\n",
    "                stemdb[word] = stemmed\n",
    "            local_index[stemmed] = local_index.setdefault(stemmed, 0)+1\n",
    "    return local_index\n",
    "\n",
    "def parseArticle(art):\n",
    "    global artcount\n",
    "    artcount += 1\n",
    "    words = []\n",
    "    if \"headline\" in art.keys():\n",
    "        words = words + art[\"headline\"].split() * 3\n",
    "        titles[art[\"docno\"]] = art[\"headline\"]\n",
    "    else : \n",
    "        titles[art[\"docno\"]] = art[\"docno\"]\n",
    "    if \"text\" in art.keys():\n",
    "        words = words + art[\"text\"].split()\n",
    "    lindex = parsestring(words)\n",
    "    mergeindex(index,lindex, art[\"docno\"])\n",
    "    updatecount(termcounts, lindex)\n",
    "\n",
    "def parsefile(document):\n",
    "    global artcount\n",
    "    local_index = {}\n",
    "    j = json.load(open(document))\n",
    "    \n",
    "    #Parallel(n_jobs=128, backend=\"threading\")(delayed(parseArticle)(art) for art in j)\n",
    "    for art in j:\n",
    "        parseArticle(art)\n",
    "\n",
    "        \n",
    "def addToIndex(doc, index, indexed, termcount):\n",
    "    if not doc in indexed.keys() :\n",
    "        local_index = parsefile(\"latimes_cleaned/\"+doc)\n",
    "        indexed[doc] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:32:07.497938",
     "start_time": "2016-11-02T14:32:07.489940"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%time parsestring('lorem impsum dolor sit amet this is a test string !%ùàéèêë'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with the indexer\n",
    "\n",
    "The block bellow will erase all the index and rebuild it from the files in the dataset. \n",
    "On my computer, it takes about 15 minutes to go through all the documents, so have a coffee machine handy if you plan to run this on a phone (it takes about 3 hours).\n",
    "\n",
    "I totally recommend you to use the loading system instead, see bellow.\n",
    "\n",
    "If, for some reason, you need to modify the index, here are a few tips :\n",
    "* If you just need to add an entry, you can do so without rebuilding the whole thing. just load the index and use addToIndex\n",
    "* If you are testing, use python's slice system to load only a few documents : replace docs with docs[:30] to load only the first 30 documents\n",
    "* If you need to build the whole index, grab a coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:43:52.101126",
     "start_time": "2016-11-02T14:38:28.956270"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "0407a813-c195-4f0c-bfd6-cbccb71fcbbb"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 730/730 [05:22<00:00,  2.19it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unorderable types: str() < bytes()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-e7749a666c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mmergePartialPLs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartialPL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prun -s \"cumulative\" buildIndex()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mA:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2165\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\python\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2084\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2085\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-55>\u001b[0m in \u001b[0;36mprun\u001b[1;34m(self, parameter_s, cell)\u001b[0m\n",
      "\u001b[1;32mA:\\python\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\python\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mprun\u001b[1;34m(self, parameter_s, cell)\u001b[0m\n\u001b[0;32m    277\u001b[0m             \u001b[0marg_str\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m         \u001b[0marg_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_splitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_with_profiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_with_profiler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\python\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36m_run_with_profiler\u001b[1;34m(self, code, opts, namespace)\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mprof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m             \u001b[0mprof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m             \u001b[0msys_exit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mA:\\python\\lib\\cProfile.py\u001b[0m in \u001b[0;36mrunctx\u001b[1;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e7749a666c5e>\u001b[0m in \u001b[0;36mbuildIndex\u001b[1;34m()\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mflushIndexToFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartialPL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mpartialPL\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mmergePartialPLs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpartialPL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'prun -s \"cumulative\" buildIndex()'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-e7749a666c5e>\u001b[0m in \u001b[0;36mmergePartialPLs\u001b[1;34m(count)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mcursors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\W+'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[0mcursors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcursors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0moperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                 \u001b[0mtempIndex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[0mtempRef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unorderable types: str() < bytes()"
     ]
    }
   ],
   "source": [
    "# This bloc recreate the whole index. Use load instead if possible\n",
    "def flushIndexToFile(fname):\n",
    "    with open(\"partialPLS/\"+str(fname),'w+b') as f:\n",
    "        for key in sorted(index.keys()):\n",
    "            j = json.dumps(index[key])\n",
    "            toWrite = key+\"\\n\"+j+\"\\n\"\n",
    "            f.write(toWrite.encode('utf8'))\n",
    "        f.flush()\n",
    "        \n",
    "def mergePartialPLs(count):\n",
    "    global ifindex\n",
    "    ifindex = {}\n",
    "    offset = 0\n",
    "    try:\n",
    "        mfid.close()\n",
    "        mfscore.close()\n",
    "    except:\n",
    "        pass # Python !\n",
    "#TODO : mutex the hell out of that stuff !\n",
    "    with open('PLByDocID', 'w+b') as f:\n",
    "        with open('PLByScore', 'w+b') as g:\n",
    "            cursors = []\n",
    "            for fname in range(0, count):\n",
    "                h =open(\"partialPLs/\"+str(fname),'r+b')\n",
    "                cursors.append([re.sub('\\W+','', h.readline().decode('utf8').rstrip()), h])\n",
    "            while len(cursors) > 0:\n",
    "                cursors = sorted(cursors, key= operator.itemgetter(0))\n",
    "                tempIndex = []\n",
    "                tempRef = 0\n",
    "                tempWord = cursors[0][0]\n",
    "                while tempRef < len(cursors) and cursors[tempRef][0] == tempWord :\n",
    "                    toParse = cursors[tempRef][1].readline().decode('utf8').rstrip()\n",
    "                    try:\n",
    "                        lind = json.loads(toParse)\n",
    "                        for el in lind:\n",
    "                            tempIndex.append(el)\n",
    "                    except:\n",
    "                        print(\"Error raised for word \"+str(tempWord)+\" in file \"+str(tempRef))\n",
    "                    \n",
    "                    cursors[tempRef][0] = cursors[tempRef][1].readline().rstrip()\n",
    "                    if cursors[tempRef][0] == b'':\n",
    "                        cursors[tempRef][1].close()\n",
    "                        del cursors[tempRef]\n",
    "                        tempRef -= 1 # Else we would skip a file\n",
    "                    tempRef += 1\n",
    "                j1 = json.dumps(sorted(tempIndex, key = operator.itemgetter(0))).encode('utf8')\n",
    "                j2 = json.dumps(sorted(tempIndex, key = operator.itemgetter(1))[::-1]).encode('utf8')\n",
    "                f.write(j1)\n",
    "                g.write(j2)\n",
    "                ifindex[tempWord] = (offset, len(j1))\n",
    "                offset += len(j1)\n",
    "            g.flush()\n",
    "        f.flush()\n",
    "\n",
    "def buildIndex():\n",
    "    docs = listdir(\"latimes_cleaned/\")\n",
    "    global index\n",
    "    global indexed\n",
    "    global termcounts\n",
    "    global titles\n",
    "    global artcount\n",
    "    index = {}\n",
    "    indexed = {}\n",
    "    termcounts = {}\n",
    "    titles = {}\n",
    "    artcount = 0\n",
    "    trig = False\n",
    "    partialPL = 0\n",
    "    try:\n",
    "        mkdir(\"partialPLs\")\n",
    "    except:\n",
    "        pass # Python !!!\n",
    "    for doc in tqdm(docs) : # I totally love tqdm.\n",
    "        addToIndex(doc, index, indexed, termcounts)\n",
    "\n",
    "        if sys.getsizeof(index) > 1200000: #Comment out to restore old behavior\n",
    "            flushIndexToFile(partialPL)\n",
    "            partialPL += 1\n",
    "            index = {}\n",
    "    if len(index)>0:        \n",
    "        flushIndexToFile(partialPL)\n",
    "        partialPL +=1\n",
    "    mergePartialPLs(partialPL)        \n",
    "\n",
    "%prun -s \"cumulative\" buildIndex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block bellow saves the whole index as a pickle file.\n",
    "This way, you can load the index afterwards, and save a precious time !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:33:54.746279",
     "start_time": "2016-11-02T14:33:54.537771"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "b32885ed-3fa8-43c2-9895-a9c9a6015f5c"
    }
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    all_index = (index, indexed, termcounts, titles, artcount, ifindex)\n",
    "    save_obj(all_index, \"indexFile_cleaneddata\")\n",
    "save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the block bellow loads all the index from disk. about 3 seconds for the whole thing on my computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:37:05.920517",
     "start_time": "2016-11-02T14:37:05.744518"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully imported 50 indexed documents\n"
     ]
    }
   ],
   "source": [
    "all_index = load_obj(\"indexFile_cleaneddata\")\n",
    "index, indexed, termcounts, titles, artcount, ifindex = all_index\n",
    "print(\"successfully imported {count} indexed documents\".format(count=len(indexed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query system\n",
    "\n",
    "Bellow is the querying system. Use it to, well, query the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:36:49.308192",
     "start_time": "2016-11-02T14:36:49.268191"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "c1542422-4a08-44c3-acdf-1a3216820bfb"
    }
   },
   "outputs": [],
   "source": [
    "with open('PLByDocID', 'r+b') as f:\n",
    "    mfid = mmap.mmap(f.fileno(),0)\n",
    "with open('PLByScore', 'r+b') as g:\n",
    "    mfscore = mmap.mmap(g.fileno(),0)\n",
    "\n",
    "def getWordPL(word):\n",
    "    global ifindex\n",
    "    try:\n",
    "        offset, length = ifindex[word]\n",
    "        mfid.seek(offset)\n",
    "        j = mfid.read(length)\n",
    "        rbind = json.loads(j.decode())\n",
    "        return rbind\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def query(request, mode=\"or\"):\n",
    "    words = request.lower().split()\n",
    "    scores = {}\n",
    "    matches = []\n",
    "    global artcount\n",
    "    for word in tqdm(words):\n",
    "        stemmed = stemmer.stem(word)\n",
    "        \n",
    "        ids = []\n",
    "        if stemmed in termcounts.keys():\n",
    "            localresults = getWordPL(stemmed.encode())\n",
    "            idf = math.log(artcount/termcounts[stemmed])\n",
    "\n",
    "            for match in localresults:\n",
    "                docid, score = match\n",
    "                ids.append(docid)\n",
    "                score = score * idf\n",
    "                scores[docid] = scores.setdefault(docid, 0) + score\n",
    "        matches.append(ids)\n",
    "    if mode == \"and\":\n",
    "        found = set(matches[0]).intersection(*matches)\n",
    "        notfound = list(set(scores)-set(found))\n",
    "        for miss in notfound:\n",
    "            del scores[miss]\n",
    "    return scores\n",
    "\n",
    "def getBestSimple(request, nbresults=10, mode=\"or\"):\n",
    "    scores = query(request, mode)\n",
    "    return sorted(scores.items(), key=operator.itemgetter(1))[:-nbresults:-1]\n",
    "\n",
    "def translateTitles(response):\n",
    "    modified = []\n",
    "    for pair in response:\n",
    "        docno, score = pair\n",
    "        modified.append((titles[docno], score))\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple queries\n",
    "\n",
    "This is where you enter the queries for now. This system supports only simple queries, composed by a list of words and a mode of selection (or or and).\n",
    "\n",
    "There is a much better query system bellow. with a lexer, a parser, parenthesis, and a few other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:37:10.976630",
     "start_time": "2016-11-02T14:37:10.969624"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "6396603b-b6c9-4ba6-9a7a-0f114f493501"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1001.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('la012289-0118', 11.992667252520594),\n",
       " ('la010589-0062', 5.996333626260297),\n",
       " ('la011190-0043', 5.996333626260297),\n",
       " ('la012090-0149', 5.996333626260297),\n",
       " ('la011190-0213', 5.996333626260297),\n",
       " ('la010190-0039', 5.996333626260297),\n",
       " ('la010490-0115', 5.996333626260297),\n",
       " ('la011890-0070', 5.996333626260297),\n",
       " ('la010289-0064', 5.996333626260297)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getBestSimple(\"towel\", mode=\"and\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex queries\n",
    "\n",
    "This other system is more advanced, and features a lexer and a parser to support complex queries with various operator and parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:37:57.451139",
     "start_time": "2016-11-02T14:37:57.445133"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parserTest = SearchQueryParser()\n",
    "def getBest(request, nbresults=10):\n",
    "    scores = parserTest.Parse(request)\n",
    "    return sorted(scores.items(), key=operator.itemgetter(1))[:-nbresults:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:37:58.038256",
     "start_time": "2016-11-02T14:37:58.024257"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('w. hollywood moves to end trash-hauling confusion  ', 60.719627957487),\n",
       " ('north county trash transfer sites urged  ', 10.20090778329254)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translateTitles(getBest('garbage collector', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:34:04.043616",
     "start_time": "2016-11-02T14:34:04.033629"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "getBest('towel', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:58:26.493430",
     "start_time": "2016-11-02T14:58:26.460425"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from http.server import BaseHTTPRequestHandler,HTTPServer\n",
    "from socketserver import ThreadingMixIn\n",
    "import threading\n",
    "import argparse\n",
    "import cgi\n",
    "\n",
    "try:\n",
    "    serv.stop()\n",
    "except:\n",
    "    pass\n",
    "class LocalData(object):\n",
    "  records = {}\n",
    " \n",
    "class HTTPRequestHandler(BaseHTTPRequestHandler):\n",
    " \n",
    "  def do_GET(self):\n",
    "    self.send_response(200)\n",
    "    self.send_header('Content-Type', 'application/json')\n",
    "    self.end_headers()\n",
    "    self.wfile.write(bytes(\"test\", 'utf8'))\n",
    "    \n",
    "    return\n",
    " \n",
    "class ThreadedHTTPServer(ThreadingMixIn, HTTPServer):\n",
    "  allow_reuse_address = True\n",
    " \n",
    "  def shutdown(self):\n",
    "    self.socket.close()\n",
    "    HTTPServer.shutdown(self)\n",
    " \n",
    "class SimpleHttpServer():\n",
    "  def __init__(self, ip, port):\n",
    "    self.server = ThreadedHTTPServer((ip,port), HTTPRequestHandler)\n",
    " \n",
    "  def start(self):\n",
    "    self.server_thread = threading.Thread(target=self.server.serve_forever)\n",
    "    self.server_thread.daemon = True\n",
    "    self.server_thread.start()\n",
    " \n",
    "  def waitForThread(self):\n",
    "    self.server_thread.join()\n",
    " \n",
    "  def addRecord(self, recordID, jsonEncodedRecord):\n",
    "    LocalData.records[recordID] = jsonEncodedRecord\n",
    " \n",
    "  def stop(self):\n",
    "    self.server.shutdown()\n",
    "    self.waitForThread()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:58:18.910214",
     "start_time": "2016-11-02T14:58:18.904218"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "serv = SimpleHttpServer(\"127.0.0.1\", 5366)\n",
    "serv.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-11-02T14:58:21.944708",
     "start_time": "2016-11-02T14:58:21.941710"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "serv.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Index and query - Reformatted data.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nav_menu": {},
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "d76c8e06-3f71-4ecd-b868-87f9254b0555",
    "theme": {
     "d3d7867b-1ee4-4a7e-836f-07ba964a2c48": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "d3d7867b-1ee4-4a7e-836f-07ba964a2c48",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         34,
         34,
         34
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         238,
         238
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         170,
         34,
         51
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         238,
         238,
         238
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Ubuntu",
       "font-size": 5
      }
     },
     "d76c8e06-3f71-4ecd-b868-87f9254b0555": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "d76c8e06-3f71-4ecd-b868-87f9254b0555",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         256,
         256,
         256
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         0,
         0,
         0
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         0,
         0,
         139
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         0,
         0,
         0
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Lato",
       "font-size": 5
      }
     },
     "ff64e434-5bb4-459e-a611-f167c1d10393": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "ff64e434-5bb4-459e-a611-f167c1d10393",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         34,
         34,
         34
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         238,
         238
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         170,
         34,
         51
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         238,
         238,
         238
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Ubuntu",
       "font-size": 5
      }
     }
    }
   }
  },
  "notify_time": "5",
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
