{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query lexer. Very beta\n",
    "\n",
    "It works rather well, almost surprisingly. Only with and or or, and parenthesis, I did not really test the quotes and not operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T09:19:08.381969",
     "start_time": "2016-09-28T09:19:08.183062"
    },
    "code_folding": [
     47
    ],
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Search query parser\n",
    "\n",
    "version 2006-03-09\n",
    "\n",
    "This search query parser uses the excellent Pyparsing module \n",
    "(http://pyparsing.sourceforge.net/) to parse search queries by users.\n",
    "-------------------------------------------------------------------------------\n",
    "Copyright (c) 2006, Estrate, the Netherlands\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification,\n",
    "are permitted provided that the following conditions are met:\n",
    "\n",
    "* Redistributions of source code must retain the above copyright notice, this\n",
    "  list of conditions and the following disclaimer.\n",
    "* Redistributions in binary form must reproduce the above copyright notice,\n",
    "  this list of conditions and the following disclaimer in the documentation \n",
    "  and/or other materials provided with the distribution.\n",
    "* Neither the name of Estrate nor the names of its contributors may be used\n",
    "  to endorse or promote products derived from this software without specific\n",
    "  prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR\n",
    "ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES\n",
    "(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; \n",
    "LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON \n",
    "ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT \n",
    "(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS \n",
    "SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "CONTRIBUTORS:\n",
    "- Steven Mooij\n",
    "- Rudolph Froger\n",
    "- Paul McGuire\n",
    "\n",
    "\n",
    "~~ End of notice\n",
    "\n",
    "I did not alter the structure of this thing a lot. Mostly modified it to work in my implementation of the index,\n",
    "which uses tuples docid + score instead of single ids. Thus some things might not work yet.\n",
    "Also hurray for global variables and definitions, because I didn't want to write more classes.\n",
    "\"\"\"\n",
    "from pyparsing import Word, alphanums, Keyword, Group, Combine, Forward, Suppress, Optional, OneOrMore, oneOf\n",
    "\n",
    "class SearchQueryParser:\n",
    "\n",
    "    def __init__(self):\n",
    "        self._methods = {\n",
    "            'and': self.evaluateAnd,\n",
    "            'or': self.evaluateOr,\n",
    "            'not': self.evaluateNot,\n",
    "            'parenthesis': self.evaluateParenthesis,\n",
    "            'quotes': self.evaluateQuotes,\n",
    "            'word': self.evaluateWord,\n",
    "            'wordwildcard': self.evaluateWordWildcard,\n",
    "        }\n",
    "        self._parser = self.parser()\n",
    "    \n",
    "    def parser(self):\n",
    "        operatorOr = Forward()\n",
    "        \n",
    "        operatorWord = Group(Combine(Word(alphanums) + Suppress('*'))).setResultsName('wordwildcard') | \\\n",
    "                            Group(Word(alphanums)).setResultsName('word')\n",
    "        \n",
    "        operatorQuotesContent = Forward()\n",
    "        operatorQuotesContent << (\n",
    "            (operatorWord + operatorQuotesContent) | operatorWord\n",
    "        )\n",
    "        \n",
    "        operatorQuotes = Group(\n",
    "            Suppress('\"') + operatorQuotesContent + Suppress('\"')\n",
    "        ).setResultsName(\"quotes\") | operatorWord\n",
    "        \n",
    "        operatorParenthesis = Group(\n",
    "            (Suppress(\"(\") + operatorOr + Suppress(\")\"))\n",
    "        ).setResultsName(\"parenthesis\") | operatorQuotes\n",
    "\n",
    "        operatorNot = Forward()\n",
    "        operatorNot << (Group(\n",
    "            Suppress(Keyword(\"not\", caseless=True)) + operatorNot\n",
    "        ).setResultsName(\"not\") | operatorParenthesis)\n",
    "\n",
    "        operatorAnd = Forward()\n",
    "        operatorAnd << (Group(\n",
    "            operatorNot + Suppress(Keyword(\"and\", caseless=True)) + operatorAnd\n",
    "        ).setResultsName(\"and\") | Group(\n",
    "            operatorNot + OneOrMore(~oneOf(\"and or\") + operatorAnd)\n",
    "        ).setResultsName(\"and\") | operatorNot)\n",
    "        \n",
    "        operatorOr << (Group(\n",
    "            operatorAnd + Suppress(Keyword(\"or\", caseless=True)) + operatorOr\n",
    "        ).setResultsName(\"or\") | operatorAnd)\n",
    "\n",
    "        return operatorOr.parseString\n",
    "\n",
    "    def evaluateAnd(self, argument):\n",
    "        left = self.evaluate(argument[0])\n",
    "        right = self.evaluate(argument[1])\n",
    "        \n",
    "        found = set(left.keys()).intersection(set(right.keys()))\n",
    "        scores = {}\n",
    "        for key in found:\n",
    "            scores[key] = left[key] + right[key]\n",
    "        return scores\n",
    "\n",
    "    def evaluateOr(self, argument):\n",
    "        scores = {}\n",
    "        for i in range(0,2):\n",
    "            localresults = self.evaluate(argument[i])\n",
    "            for key in localresults.keys():\n",
    "                    scores[key] = scores.setdefault(key, 0) + localresults[key]\n",
    "        return scores\n",
    "\n",
    "    def evaluateNot(self, argument):\n",
    "        return self.GetNot(self.evaluate(argument[0]))\n",
    "\n",
    "    def evaluateParenthesis(self, argument):\n",
    "        return self.evaluate(argument[0])\n",
    "\n",
    "    def evaluateQuotes(self, argument):\n",
    "        r = Set()\n",
    "        search_terms = []\n",
    "        for item in argument:\n",
    "            search_terms.append(item[0])\n",
    "            if len(r) == 0:\n",
    "                r = self.evaluate(item)\n",
    "            else:\n",
    "                r = r.intersection(self.evaluate(item))\n",
    "        return self.GetQuotes(' '.join(search_terms), r)\n",
    "\n",
    "    def evaluateWord(self, argument):\n",
    "        return self.GetWord(argument[0])\n",
    "\n",
    "    def evaluateWordWildcard(self, argument):\n",
    "        return self.GetWordWildcard(argument[0])\n",
    "        \n",
    "    def evaluate(self, argument):\n",
    "        return self._methods[argument.getName()](argument)\n",
    "\n",
    "    def Parse(self, query):\n",
    "        #print self._parser(query)[0]\n",
    "        return self.evaluate(self._parser(query)[0])\n",
    "\n",
    "    def GetWord(self, word):\n",
    "        return query(word)\n",
    "\n",
    "    def GetWordWildcard(self, word):\n",
    "        return query(word)\n",
    "\n",
    "    def GetQuotes(self, search_string, tmp_result):\n",
    "        return query(search_string, mode=\"and\")\n",
    "\n",
    "    def GetNot(self, not_set):\n",
    "        return Set().difference(not_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "204184b1-84df-45ed-ab85-d89af73f01d1"
    }
   },
   "source": [
    "# Indexer and querying system\n",
    "\n",
    "This notebook provides a fonctionnal system to index a bunch of text document, and to run fast text queries against the index.\n",
    "\n",
    "Author : Anthony Rossi\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T09:19:36.965533",
     "start_time": "2016-09-28T09:19:36.959529"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "f983e209-828d-4237-beac-fd05f1439232"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import *\n",
    "from tqdm import *\n",
    "import math\n",
    "import operator\n",
    "import pickle\n",
    "import json\n",
    "import sys\n",
    "import mmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions and global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T10:59:43.771167",
     "start_time": "2016-09-28T10:59:43.766162"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "f9d1e156-1248-47ae-9b48-5a2e742b57b2"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "docs = listdir(\"latimes_cleaned\")\n",
    "index = {}\n",
    "indexed = {}\n",
    "termcounts = {}\n",
    "titles = {}\n",
    "artcount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T10:59:44.362156",
     "start_time": "2016-09-28T10:59:44.356139"
    },
    "collapsed": true,
    "nbpresent": {
     "id": "5673b0d2-fd2f-495a-b8a7-9dc0781912f0"
    }
   },
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open('data_cache/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('data_cache/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T11:00:24.304068",
     "start_time": "2016-09-28T11:00:24.253033"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "ddeb4682-6fe5-44d7-ba78-8e602ead9385"
    }
   },
   "outputs": [],
   "source": [
    "def mergeindex(globalindex, localindex, docid):\n",
    "    for key in localindex.keys():\n",
    "        globalindex.setdefault(key,[]).append((docid, localindex[key]))\n",
    "\n",
    "def updatecount(globalcounts, localcounts):\n",
    "    for key in localcounts.keys():\n",
    "        globalcounts[key] = globalcounts.setdefault(key, 0) + 1\n",
    "\n",
    "def parsestring(words):\n",
    "    local_index = {}\n",
    "    for word in words:\n",
    "        if not word in cachedStopWords:\n",
    "            stemmed = stemmer.stem(word)\n",
    "            local_index[stemmed] = local_index.setdefault(stemmed, 0)+1\n",
    "    return local_index\n",
    "\n",
    "\n",
    "def parsefile(document):\n",
    "    global artcount\n",
    "    local_index = {}\n",
    "    j = json.load(open(document))\n",
    "    for art in j:\n",
    "        artcount += 1\n",
    "        words = []\n",
    "        if \"headline\" in art.keys():\n",
    "            words = words + word_tokenize(art[\"headline\"].lower()) * 3\n",
    "            titles[art[\"docno\"]] = art[\"headline\"]\n",
    "        else : \n",
    "            titles[art[\"docno\"]] = art[\"docno\"]\n",
    "        if \"text\" in art.keys():\n",
    "            words = words + word_tokenize(art[\"text\"].lower())\n",
    "        lindex = parsestring(words)\n",
    "        mergeindex(index,lindex, art[\"docno\"])\n",
    "        updatecount(termcounts, lindex)\n",
    "        \n",
    "        \n",
    "def addToIndex(doc, index, indexed, termcount):\n",
    "    if not doc in indexed.keys() :\n",
    "        local_index = parsefile(\"latimes_cleaned/\"+doc)\n",
    "        indexed[doc] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interaction with the indexer\n",
    "\n",
    "The block bellow will erase all the index and rebuild it from the files in the dataset. \n",
    "On my computer, it takes about 15 minutes to go through all the documents, so have a coffee machine handy if you plan to run this on a phone.\n",
    "\n",
    "I totally recommend you to use the loading system instead, see bellow.\n",
    "\n",
    "If, for some reason, you need to modify the index, here are a few tips :\n",
    "* If you just need to add an entry, you can do so without rebuilding the whole thing. just load the index and use addToIndex\n",
    "* If you are testing, use python's slice system to load only a few documents : replace docs with docs[:30] to load only the first 30 documents\n",
    "* If you need to build the whole index, grab a coffee.\n",
    "\n",
    "For now the whole thing sits in the RAM, just because. Obviously, I will have to change that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T11:01:42.078095",
     "start_time": "2016-09-28T11:00:24.967604"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "0407a813-c195-4f0c-bfd6-cbccb71fcbbb"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "# This bloc recreate the whole index. Use load instead if possible\n",
    "\n",
    "docs = listdir(\"latimes_cleaned/\")\n",
    "index = {}\n",
    "indexed = {}\n",
    "termcounts = {}\n",
    "titles = {}\n",
    "artcount = 0\n",
    "for doc in tqdm(docs[:2]) : # I totally love tqdm.\n",
    "    addToIndex(doc, index, indexed, termcounts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block bellow saves the whole index as a pickle file.\n",
    "This way, you can load the index afterwards, and save a precious time ! (see what I did here ? Cause building the index takes time, and it's a file that you're saving, so saving time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T11:01:48.771151",
     "start_time": "2016-09-28T11:01:48.494942"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "b32885ed-3fa8-43c2-9895-a9c9a6015f5c"
    }
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    all_index = (index, indexed, termcounts, titles, artcount)\n",
    "    save_obj(all_index, \"indexFile_cleaneddata\")\n",
    "save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the block bellow loads all the index from disk. about 3 seconds for the whole thing on my computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T09:30:41.282923",
     "start_time": "2016-09-28T09:30:39.160426"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully imported 60 indexed documents\n"
     ]
    }
   ],
   "source": [
    "all_index = load_obj(\"indexFile_cleaneddata\")\n",
    "index, indexed, termcounts, titles, artcount = all_index\n",
    "print(\"successfully imported {count} indexed documents\".format(count=len(indexed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T09:48:11.497819",
     "start_time": "2016-09-28T09:48:11.240641"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query system\n",
    "\n",
    "Bellow is the querying system. Use it to, well, query the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T11:06:22.104133",
     "start_time": "2016-09-28T11:06:22.074113"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "c1542422-4a08-44c3-acdf-1a3216820bfb"
    }
   },
   "outputs": [],
   "source": [
    "def query(request, mode=\"or\"):\n",
    "    words = request.lower().split()\n",
    "    scores = {}\n",
    "    matches = []\n",
    "    global artcount\n",
    "    for word in tqdm(words):\n",
    "        stemmed = stemmer.stem(word)\n",
    "        localresults = index.get(stemmed)\n",
    "        ids = []\n",
    "        if stemmed in termcounts.keys():\n",
    "            idf = math.log(artcount/termcounts[stemmed])\n",
    "\n",
    "            for match in localresults:\n",
    "                docid, score = match\n",
    "                ids.append(docid)\n",
    "                score = score * idf\n",
    "                scores[docid] = scores.setdefault(docid, 0) + score\n",
    "        matches.append(ids)\n",
    "    if mode == \"and\":\n",
    "        found = set(matches[0]).intersection(*matches)\n",
    "        notfound = list(set(scores)-set(found))\n",
    "        for miss in notfound:\n",
    "            del scores[miss]\n",
    "    return scores\n",
    "\n",
    "def getBestSimple(request, nbresults=10, mode=\"or\"):\n",
    "    scores = query(request, mode)\n",
    "    return sorted(scores.items(), key=operator.itemgetter(1))[:-nbresults:-1]\n",
    "\n",
    "def translateTitles(response):\n",
    "    modified = []\n",
    "    for pair in response:\n",
    "        docno, score = pair\n",
    "        modified.append((titles[docno], score))\n",
    "    return modified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple queries\n",
    "\n",
    "This is where you enter the queries for now. This system supports only simple queries, composed by a list of words and a mode of selection (or or and).\n",
    "\n",
    "There is a much better query system bellow. with a lexer, a parser, parenthesis, and a few other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T11:06:22.582639",
     "start_time": "2016-09-28T11:06:22.573633"
    },
    "collapsed": false,
    "nbpresent": {
     "id": "6396603b-b6c9-4ba6-9a7a-0f114f493501"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('la010189-0087', 4.955827057601261), ('la010190-0039', 4.955827057601261)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getBestSimple(\"towel\", mode=\"and\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex queries\n",
    "\n",
    "This other system is more advanced, and features a lexer and a parser to support complex queries with various operator and parenthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T11:06:23.121117",
     "start_time": "2016-09-28T11:06:23.116110"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "parserTest = SearchQueryParser()\n",
    "def getBest(request, nbresults=10):\n",
    "    scores = parserTest.Parse(request)\n",
    "    return sorted(scores.items(), key=operator.itemgetter(1))[:-nbresults:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-09-28T11:06:23.622593",
     "start_time": "2016-09-28T11:06:23.610571"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('eritrean rebel campaign backed by hidden factories, ethiopian pows  ',\n",
       "  4.955827057601261),\n",
       " ('firefighters by fireplaces remodel: new agua dulce firehouse began life as family home. ',\n",
       "  4.955827057601261)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translateTitles(getBest('towel', 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('la010189-0087', 4.955827057601261), ('la010190-0039', 4.955827057601261)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getBest('towel', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ifindex = {}\n",
    "with open('testsavemmap', w+b):\n",
    "    for word in index:\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "gist": {
   "data": {
    "description": "Index and query - Reformatted data.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "d76c8e06-3f71-4ecd-b868-87f9254b0555",
    "theme": {
     "d3d7867b-1ee4-4a7e-836f-07ba964a2c48": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "d3d7867b-1ee4-4a7e-836f-07ba964a2c48",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         34,
         34,
         34
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         238,
         238
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         170,
         34,
         51
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         238,
         238,
         238
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Ubuntu",
       "font-size": 5
      }
     },
     "d76c8e06-3f71-4ecd-b868-87f9254b0555": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "d76c8e06-3f71-4ecd-b868-87f9254b0555",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         256,
         256,
         256
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         0,
         0,
         0
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         0,
         0,
         139
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         0,
         0,
         0
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "News Cycle",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "News Cycle"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Lato",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Lato",
       "font-size": 5
      }
     },
     "ff64e434-5bb4-459e-a611-f167c1d10393": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "ff64e434-5bb4-459e-a611-f167c1d10393",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         34,
         34,
         34
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         238,
         238
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         170,
         34,
         51
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         238,
         238,
         238
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Ubuntu",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Ubuntu"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       },
       "p": {
        "color": "mainColor",
        "font-family": "Ubuntu",
        "font-size": 5
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Ubuntu",
       "font-size": 5
      }
     }
    }
   }
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
